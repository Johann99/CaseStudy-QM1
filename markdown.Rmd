---
title: 'Fallstudie: Robinson Club'
author: "Piet"
date: "15 2 2020"
output: html_document
---


# Zielformulierung: Ist die Einführung von Bionahrung beim Robinson Club aus betriebswirtschaftlicher Sicht strategisch sinvoll?

## Fragestellungen:

(1) Welchen Einfluss hat das Essen auf das Wohlbefinden der G ̈aste? (Stellen- wert des Essens im Vergleich zu den sonstigen Angeboten ROBINSONs)
(2) IsteinAngebotvonBionahrungdenG ̈astenwichtig/erwu ̈nscht/erwartet? (Wichtigkeit von Bionahrung)
(3) Was bedeutet Bio fu ̈r die G ̈aste? (Herausstellen der Elemente von Bion- ahrung und der Wichtigkeit dieser Elemente)
(4) Sind die G ̈aste bereit fu ̈r ein Angebot von Bionahrung einen Aufschlag zu zahlen? (Preissensitivit ̈at der G ̈aste fu ̈r ein zus ̈atzliches Angebot von Bionahrung)
(5) Wem genau ist das Angebot von Bionahrung wichtig? Wie unterscheiden sich diese Personen? (Zielgruppenidentifikation bezu ̈glich Bionahrung)
(6) Bei welchen Lebensmittelarten ist das Angebot von Bio besonders wichtig /
unwichtig? (Wichtigkeit von Bio bei unterschiedlichen Lebensmittelarten)
(7) Welche Biosiegel sind den G ̈asten bekannt? (Bekanntheit Biosiegel)

## Hypothesen:

(1) Personen mit Kindern bevorzugen Bionahrung eher als Personen ohne Kinder. 
(2) Robinson G ̈aste sind bereit fu ̈r Bionahrung einen Aufschlag zu zahlen.
(3) Bionahrung besitzt das Potenzial ROBINSON als Marke zu st ̈arken.

## Packages importieren 

```{r}

install.packages('tidyverse')
library(tidyverse)

install.packages('dplyr')
library(dplyr)

install.packages('data.table')
library(data.table)

install.packages('VIM')
library(VIM)

install.packages('class')
library(class)

install.packages("factoextra")
library(factoextra)

install.packages('ggplot2')
library(ggplot2)

```


## Daten importieren und schnellen Überblick verschaffen


```{r}
fragebogen = read.csv('fallstudie.csv')

sum(is.na(fragebogen))

str(fragebogen)

head(fragebogen)
```

## CLEANING 

### Umgang mit fehlenden Werten

#### Drei verschiedene Arten von fehlenden Daten 

1. Missing completely at random (MCAR):
  Das Fehlen der Daten steht in keiner Beziehung zu den anderen Daten. Wenn man vorhersagen 
  kann, welche Daten fehlen, dann kann man MCAR ausschließen. Das fehlen der Daten ist somit
  komplett zufällig.

2. Missing at random (MAR): 
  Die Idee hinter dieser Art von fehlenden Daten ist, dass wir die fehlenden Daten 
  vorhersagen können anhand des Datensets. 

3. Missing not at random (nonignorable)
  Die fehlenden Daten haben ein Muster, bsp Probanden antworten auf eine bestimmte Frage nicht, weil Sie eine 
  bestimmte Eigenschaft aufweisen.
  In diesem Fall können wir keine Aussage oder Prognose für die fehlenden Werte machen. Es 
  ist weder MAR noch MCAR. 


#### Drei verschiedene Methoden mit fehlenden Daten umzugehen:

1.FEHLENDE DATEN LÖSCHEN  
  Wenn NA's nur wenige (max 0,5 %) von Erhebung macht droppen Sinn, da einfach und 
  Testergebnis nicht zu sehr verzerrt wird. na.omit() wäre der Code-Snippet. Dabei würde 
  wenn überhaupt eine reihenweise Löschung Sinn machen, da wir für die Analyse eines 
  Befragten die ganzen Werte brauchen. Dies führt allerdings zur Löschung 
  des komplette Datensets. Somit kommt diese Methode für uns nicht in Frage.
  
2.FEHLENDEN DATEN MIT TEST STATISTIKEN FÜLLEN
  Wenn mean() dann darf der prozentuale Anteil von NA's auch nicht so hoch sein (kann man 
  hier einfach den Default Alpha Value nehmen?)
  Es verringert die Varianz der Erhebungsdaten, da diese geglättet werden durch das 
  arithemtische Mittel.
  Extreme Ausreißer können den mean() zu stark beeinflussen und das Ergebniss verzerren. 
  Hier sind die Zahlen kategorisch vorgegeben, somit kann es keine größeren Ausreißer geben. 
  
3.FEHLENDE DATEN MIT MACHINE LEARNING ALGORITHMEN BESTIMMEN
  Ein Beispiel für ein einfach zu implementierenden Algorithmus wäre KNN (K-Nearest-Neighbor).
  Idee hinter KNN: Die fehlenden Werte können mit den Werte die diesem Wert in einem 
  zweidimensionalen Koordinatensystem am nähesten Liegen ermittelt werden. 
  KNN kann unter bestimmten Vorraussetzungen sehr viel genauer sein als das arithmetische Mittel. Allerdings ist es  
  sehr sensitiv was Ausreißer anbelangt. 
  Für uns könnten diese Methodik sehr interessant sein, da wir keine Ausreißer im 
  klassischen Sinne haben können, da
  die Normierung teilweise schon vorgegeben ist. Dieser Algorithmus kann für stetig und diskrete Daten 
  genutzt werden.
  
Für die Fragen mit einer Normierung von 1-7 werden wir eine KNN-Imputation durchführen, da wir davon ausgehen können, dass diese Daten zufällig fehlen, da wir keine Muster in den fehlenden Angaben feststellen konnten. Darüber hinaus haben wir in unserem Numerischen Datensatz (numeric_fragebogen) auch Daten mit völlig verschiedenen Normierungen, welches die Gefahr birgt, dass fehlende Daten falsch prognostiziert werden. 


## Welche Spalten sind von NA's betroffen?

Durch die prozentuale Berechnung der NA's pro Spalte, verschaffen wir uns einen Überblick über die fehlenden NA's und haben direkt ein gutes Fundament, welches uns hilft zu entscheiden wie wir mit den fehlenden Werten umgehen können.

```{r}

contains_any_na = sapply(fragebogen, function(x) any(is.na(x)))
column_names_na = names(fragebogen)[contains_any_na]

## df das anzeigt wie viel Prozent NA pro Spalte vorhanden sind
perc_na = sapply(fragebogen, function(x) sum(is.na(x))/count(fragebogen))
perc_na = as.data.frame(perc_na)
perc_na


```

## Welche Spalten (Fragen) können wir ausschließen? 

Dabei können wir aus dem Fragebogen schon erkennen, dass bestimmte Fragen Freitext als Antwort haben. Wir müssen alle Spalten exkludieren, welche auf 'txt' oder auf 'txt_val' enden. Diese Spalten müssen seperat betrachtet werden da sie keine numerischen Daten enthalten und für Kalkulationen für arithemtische Mittelwerte oder Modalwerte nicht geeignet sind. 
Des Weiteren haben die beiden Anfangsdaten "Ort" und "ID" für uns keine Relevanz. Die Text-Antworten von Frage 17 und Frage 24 sind ebenfalls vorerst für uns nicht von Interesse. Die Nominal skaliserte Frage 20 muss ebenfalls ausgeschlossen werden. 

```{r}

#drop von den Text Daten

#welche Spalten haben die Endung 'txt'?
fragebogendt<-as.data.table(fragebogen)
fragebogenneu<-fragebogendt[,grep("txt",colnames(fragebogendt))]
fragebogenneu
numericfragebogen<-fragebogen[-fragebogenneu]

# einzelne nicht numerische Daten (oder im Fall von f_20 nominal skalierte Daten) werden nochmal herausgefiltert und entfernt 
numericfragebogen = numericfragebogen[-c(1:2,129,122)]
#f17_Comment ausschließen
numericfragebogen$f17_Comment = NULL

# drop von denen dessen Normierung nicht 1-7 ist 
sc_1_7_fragebogen = select(numericfragebogen, -c(f21:f25_2,f11_2:f13_3,f8:f11_1))

```

Damit haben wir die Daten die eine Normierung von 1-7 für die KNN-Imputation bereitgestellt. NA's von anderen relevanten Spalten werden in den Einzelfällen separat betrachtet und entsprechend manipuliert. Dafür dient vor allem die Variable perc_na, welche Auskunft über den prozentualen Anteil an fehlenden Werte in der entsprechenden Spalte angibt. 




## KNN Imputation
Im folgenden führen wir die KNN-Imputation für das entpsrechenden Datenset sc_1_7_fragebogen durch. Dabei wird bei der Imputation weitere Spalten mit boolean Werte erstellt. Diese Spalten sind für unsere weiteren Berechnung unerheblich, aus diesem Grund werden sie aus dem Datenset entfernt. Eine neues Datenset ist entstanden, welches wir knn_fragebogen nennen.
Zum Schluss haben wir noch einen kleinen visuellen Vergleich angestellt, indem wir Spalten aus dem alten Datensatz mit dem knn-bereinigten Datensatz verglichen haben. Dabei ging es vor allem darum, zu schauen ob die KNN-Imputation fehlerhaft war oder bestimmte Ergebnisse völlig außerhalb des Datensatzes sind, beispielsweise neue Ausreißer mit 7 oder 1 erstellt. 

```{r}
# skalierung von 1-7 in einem df sc_1_7_fragebogen als knn_fragebogen gespeichert um fehlende Werte durch KNN zu ermitteln (Imputation)
# k=sqrt(count(fragebogen)

knn_fragebogen = kNN(sc_1_7_fragebogen,k=sqrt(count(fragebogen)))

# zusätzlichen Spalten, die durch den algo knn erstellt wurden, droppen 
knn_fragebogen = select(knn_fragebogen, -(f3_3_imp:f19_10_imp))

# double check ob auch wirklich alle NA's imputiert wurden
sum(is.na(knn_fragebogen))

# test ob Imputation statistisch erfolgreich

# Zum visuellen Vergleich wie gut KNN Algo funktioniert hat
#mit ~ 1,3 % NA's
plot(fragebogen$f4_11)
plot(knn_fragebogen$f4_11)

#mit ~ 10 % NA's
plot(fragebogen$f4_5)
plot(knn_fragebogen$f4_5)

#mit ~ 25 % NA's
plot(fragebogen$f6_4)
plot(knn_fragebogen$f6_4)




```

## Frage 1: Welchen Einfluss hat das Essen auf das Wohlbefinden der Gäste? (Stellen- wert des Essens im Vergleich zu den sonstigen Angeboten ROBINSON


```{r}

barplot(table(essen_wohlbefinden) , main = "Wichtigkeit des Essens",xlab = "Wichtigkeit", ylab = "Anzahl der befragten Gäste", space = 1, cex.axis = 1, cex.names = 1, cex.lab = 1, cex.main = 1.5)


# Essen ist den befragten Gästen sehr wichitg
MW4.1 <- mean(knn_fragebogen$f4_1)
MW4.2 <- mean(knn_fragebogen$f4_2)
MW4.3 <- mean(knn_fragebogen$f4_3)
MW4.4 <- mean(knn_fragebogen$f4_4)
MW4.5 <- mean(knn_fragebogen$f4_5)
MW4.6 <- mean(knn_fragebogen$f4_6)
MW4.7 <- mean(knn_fragebogen$f4_7)
MW4.8 <- mean(knn_fragebogen$f4_8)
MW4.9 <- mean(knn_fragebogen$f4_9)
MW4.10 <- mean(knn_fragebogen$f4_10)
MW4.11<- mean(knn_fragebogen$f4_11)
MW4.12<- mean(knn_fragebogen$f4_12)
MW4.13 <- mean(knn_fragebogen$f4_13)
MW4.14 <- mean(knn_fragebogen$f4_14)

MWVektorEssen <- c(MW4.1,MW4.2,MW4.3,MW4.4,MW4.5,MW4.6,MW4.7,MW4.8,MW4.9,MW4.10,MW4.11,MW4.12,MW4.13,MW4.14)
barplot(MWVektorEssen, main = "Vergleich der Angebote",xlab = "Angebote", ylab = "Wichtigkeit", space = 1, cex.axis = 1, cex.names = 1, cex.lab = 1, cex.main = 1.5)
```

**Angebot 11 (Essen) ist den befragten Gästen am wichtigsten im Vergleich zu dem restlichen Angebot**


## Frage 2: Ist ein Angebot von Bionahrung den Gästen wichtig/erwünscht/erwartet? (Wichtigkeit von Bionahrung)
```{r}
essen_bionahrung = knn_fragebogen$f4_13
barplot(table(essen_bionahrung), main = "Wichtigkeit von Bionahrung",xlab = "Wichtigkeit", ylab = "Anzahl der befragten Gäste", space = 1, cex.axis = 1, cex.names = 1, cex.lab = 1, cex.main = 1.5)
```


**Bionahrung ist den Gästen wichtig**


## Frage 3: Was bedeutet Bio fu ̈r die G ̈aste? (Herausstellen der Elemente von Bion- ahrung und der Wichtigkeit dieser Elemente) 

```{r}
bedeutung_bio = cbind(knn_fragebogen$f15_1,
                      knn_fragebogen$f15_2,
                      knn_fragebogen$f15_3,
                      knn_fragebogen$f15_4,
                      knn_fragebogen$f15_5,
                      knn_fragebogen$f15_6,
                      knn_fragebogen$f15_7,
                      knn_fragebogen$f15_8,
                      knn_fragebogen$f15_9,
                      knn_fragebogen$f15_10,
                      knn_fragebogen$f15_11,
                      knn_fragebogen$f15_12,
                      knn_fragebogen$f15_13,
                      knn_fragebogen$f15_14,
                      knn_fragebogen$f15_15,
                      knn_fragebogen$f15_16)

bedeutung_bio_names = c('Guter Geschmack',
                        'Frische und Reife',
                        'Gesundheitsbewusste Ernährung',
                        'Hochwertige Nahrung',
                        'Abwechslungsreiche Nahrung',
                        'Sportlichkeit',
                        'Individualität',
                        'Wohlfühlen',
                        'Im Trend',
                        'Naturbelassenheit',
                        'Regionale Herkunft',
                        'Genuss',
                        'artgerechte Tierhaltung',
                        'Auschluss von Gentechnik',
                        'geprüfte Qualität',
                        'Gutes Preis-/Leistungsverhältnis')

bedeutung_bio = as.data.table(bedeutung_bio)
colnames(bedeutung_bio) <- bedeutung_bio_names

# mittelwerte der einzelnen Attribute bilden
bedeutung_bio_means = colMeans(bedeutung_bio) 

#plot
plot(bedeutung_bio_means)

# starke Assoziation mit Mittelwert kleiner gleich 2



```





## Frage 4: Sind die G ̈aste bereit fu ̈r ein Angebot von Bionahrung einen Aufschlag zu zahlen? (Preissensitivit ̈at der G ̈aste fu ̈r ein zus ̈atzliches Angebot von Bionahrung)

```{r}
price_sensitivity = numericfragebogen$f17 
price_sensitivity = as.data.table(price_sensitivity)
price_sensitivity = na.omit(price_sensitivity)


#Wie viele n's vor dem droppen von NA Reihen? --> 219
length(numericfragebogen$f17)

#Wie viele n's? --> 100 
count(price_sensitivity)

#Wie viele würden überhaupt mehr bezahlen? --> 66 Personen 
ps_0 = price_sensitivity[price_sensitivity>0, .N]

#Wie viele würden mehr als 3 % bezahlen? --> 47 Personen
ps_3 = price_sensitivity[price_sensitivity>3, .N]
u_ps_3 = ps_3 * 0.03 


#Wie viele würden mehr als 5 % bezahlen? --> 26 Personen
ps_5 = price_sensitivity[price_sensitivity>5, .N]
u_ps_5 = ps_5 * 0.05

#Wie viele würden mehr als 10 % bezahlen? --> 7 Personen
ps_10 = price_sensitivity[price_sensitivity>10, .N]
u_ps_10 = ps_10 * 0.1

#Wie viele würden mehr als 15 % bezahlen? --> 5 Personen
ps_15 = price_sensitivity[price_sensitivity>15, .N]
u_ps_15 = ps_15 * 0.15

#Wie viele würden mehr als 20 % bezahlen? --> 2 Personen 
ps_20 = price_sensitivity[price_sensitivity>20, .N]
u_ps_20 = ps_20 * 0.2

#Ergebnisse in einen Vektor packen
all_ps = c(ps_3, ps_5, ps_10, ps_15, ps_20)
all_u_ps = c(u_ps_3,u_ps_5,u_ps_10,u_ps_15,u_ps_20)

#barplot in absoluten Zahlen
barplot(all_ps)
#barplot in Prozenten, wir müssen davon ausgehen, dass diejenigen die nicht geantwortet haben, keinen Aufschlag zahlen würden
barplot(all_ps/length(numericfragebogen$f17))

#barplot Umsatz für jede Erhöhung --> Zeigt welche Prozenterhöhung sich lohnen würde wenn man die prozentuale Erhöhung und die Kaufbereitschaft der Kunden betrachtet
barplot(all_u_ps)







```

# Frage 5: Wem genau ist das Angebot von Bionahrung wichtig? Wie unterscheiden sich diese Personen? (Zielgruppenidentifikation bezüglich Bionahrung)

```{r}

head(numericfragebogen)
clusterfragebogen<-numericfragebogen[,c(3,132:122,28)]
clusterfragebogen
clusterfragebogen<-clusterfragebogen[,-c(4:9)]
clusterwithoutNA<-na.omit(clusterfragebogen)
wss <- 0
# Elbow Method
for (i in 1:15) {
  km.out <- kmeans(clusterwithoutNA, centers = i, nstart = 20, iter.max = 50)
  wss[i] <- km.out$tot.withinss
}
#Scree Plot
plot(1:15, wss, type = "b", 
     xlab = "Clusters", 
     ylab = "Within groups sum of squares")
k <- 3
km.out <- kmeans(clusterwithoutNA, centers = k, nstart = 20, iter.max = 50)
# View 
km.out
# Plot von der Häufgkeit wie oft die Kunden schon in RobinsonClub gereist sind und wie Alt sie sind
plot(clusterwithoutNA[, c("f22", "f1")],
     col = km.out$cluster,
     main = paste("k-means clustering of RobinsonClub", k, "clusters"),
     xlab = "BedeutungBio", ylab = "Häufigkeit im RobinsonClub")


#ALTERNATIVE


#Frage5
#1.Filtern nach Personen, welche Bio als wichtig ansehen und weclhe Bio als unwichtig ansehen.
Biowichtig<-numericfragebogen[f4_13<=3]
Biounwichtig<-numericfragebogen[f4_13>3]
#2. die Demografischen Daten aus den filtern
Biowichtig<-Biowichtig[,c(2,132:122)]
Biounwichtig<-Biounwichtig[,c(2,132:122)]
#3. identifizieren des Durschnittlichen Einkommens
EkBiowichtig<-Biowichtig[,mean(f26,na.rm=TRUE)]
EkBiounwichtig<-Biounwichtig[,mean(f26,na.rm=TRUE)]
#4.Durschnittliches Alter 
AlterBioWichtig<-Biowichtig[,mean(f22, na.rm=TRUE)]
AlterBioUnwichtig<-Biounwichtig[,mean(f22, na.rm=TRUE)]
#In welchen der beiden Orten 
OrtBioWichtig<-Biowichtig[,mean(Ort, na.rm=TRUE)]
ortBioUnwichtig<-Biounwichtig[,mean(Ort, na.rm=TRUE)]
#woher kommen die Kunden 
WohnortBioWichtig<-Biowichtig[,.N,f25_1]
WohnortBioUnwichtig<-Biounwichtig[,.N,f25_1]
#Bildungsabschluss
BildungBioWichtig<-Biowichtig[,mean(f20,na.rm = TRUE)]
BildungBioUnwichtig<-Biounwichtig[,mean(f20,na.rm=TRUE)]
#Geschlecht
GeschlechtBiowichtig<-Biowichtig[,.N,f21]
GeschlechtBioUnwichtig<-Biounwichtig[,.N,f21]

```



## Frage 6: Bei welchen Lebensmittelarten ist das Angebot von Bio besonders wichtig /unwichtig? (Wichtigkeit von Bio bei unterschiedlichen Lebensmittelarten)
```{r}
MW16.1 <- mean(knn_fragebogen$f16_1)
MW16.2 <- mean(knn_fragebogen$f16_2)
MW16.3 <- mean(knn_fragebogen$f16_3)
MW16.4 <- mean(knn_fragebogen$f16_4)
MW16.5 <- mean(knn_fragebogen$f16_5)
MW16.6 <- mean(knn_fragebogen$f16_6)
MW16.7 <- mean(knn_fragebogen$f16_7)
MW16.8 <- mean(knn_fragebogen$f16_8)
MW16.9 <- mean(knn_fragebogen$f16_9)

MWVektorBionahrung <- c(MW16.1,MW16.2,MW16.3,MW16.4,MW16.5,MW16.6,MW16.7,MW16.8,MW16.9)


barplot(MWVektorBionahrung, main = "Wichtigkeit von Bio bei unterschiedlichen Lebensmittelarten",xlab = "Lebensmittelkategorien", ylab = "Wichtigkeit", space = 1, cex.axis = 1, cex.names = 1, cex.lab = 1, cex.main = 1)
```

**Bei Gemüse & Salat (2), Obst (3) und Fleischprodukten (5) ist Bio für die Gäste wichtig. Bei Süßigkeiten (7), Gewürzen (8) und bei den Getränken (9) eher nicht.**



## Frage 7: Welche Biosiegel sind den G ̈asten bekannt? (Bekanntheit Biosiegel)

```{r}

#wie viele NA's pro Spalte? 
na_12_n = perc_na[perc_na$f12_1:perc_na$f12_9]

#dt kreieren
dt_f12 = as.data.table(cbind(fragebogendt$f12_1,
                 fragebogendt$f12_2,
                 fragebogendt$f12_3,
                 fragebogendt$f12_4,
                 fragebogendt$f12_5,
                 fragebogendt$f12_6,
                 fragebogendt$f12_7,
                 fragebogendt$f12_8,
                 fragebogendt$f12_9))



#drop na
dt_f12 = na.omit(dt_f12)

dt_f12_count = apply(dt_f12, 2, function(x) sum(x))


#plot
barplot(dt_f12_count)


```



# Hypothesen 

## 1 Hypothese: Personen mit Kindern bevorzugen Bionahrung eher als Personen ohne Kinder.

H0: Personen mit Kindern bevorzugen Bionahrung nicht eher als Personen ohne Kinder.
H1: Personen mit Kindern bevorzugen Bionahrung eher als Personen ohne Kinder.

```{r}
#Wie kommen wir an alle Personen die Kinder haben? --> Frage 2.3 sehr passend da bei der niedrigen prozentualen Anzahl an fehlenden Werten Reihen gedropped werden können.

# Annahme: Wer mit Familie kommt, kommt auch mit Kindern

# Frage 9
preferences_bio = as.data.table(fragebogen$f9)


# Frage 2
bio_children = as.data.table(fragebogen$f2)
#replacing 0 with NA
bio_children[bio_children == 0] <- NA

#datasets verbinden 
merge_p_b = cbind(bio_children, preferences_bio)
#Spalten Namen ändern
colnames(merge_p_b) = c('bio_children','preferences_bio')

#wie viele NA's pro Spalte? 
perc_na$f9.n #0.04 % NA
perc_na$f2.n #keine NA

#es kann bei so einer geringen Anzahl an NA's Reihen gedroped werden 
merge_p_b_na = na.omit(merge_p_b)


#filtern nach denen die bio mögen
#bio_mögen_u.kinder = merge_p_b_na[merge_p_b_na$preferences_bio < 3 & merge_p_b_na$bio_children == 3]

####################

#Kinder neu definiert

kinder_bio_all = cbind(fragebogen$f23_1, fragebogen$f23_2, fragebogen$f23_3, fragebogen$f23_4, preferences_bio)
# neue spalte die zählt wie viele NA pro Reihe
kinder_bio_all$na_count <- apply(kinder_bio_all, 1, function(x) sum(is.na(x)))

kinder_bio_all =  as.data.table(kinder_bio_all) 
colnames(kinder_bio_all) = c('1Ki','2Ki','3Ki','4Ki','bio','na_count')



# definiert df mit und ohne Kinder
# keine_kinder_mögen = kinder_bio_all[kinder_bio_all$na_count==4 & kinder_bio_all$bio < 3]
# keine_kinder_n_mögen = kinder_bio_all[kinder_bio_all$na_count==4 & kinder_bio_all$bio > 2]

# kinder und keine kinder und dann mittelwert von bio ermitteln 
keine_kinder = kinder_bio_all[kinder_bio_all$na_count==4]
kinder = kinder_bio_all[kinder_bio_all$na_count!=4]

# drop na und dt erstellen
kinder_bio = as.data.table(kinder$bio)
kinder_bio = na.omit(kinder$bio)

keine_kinder_bio = as.data.table(keine_kinder$bio)


# mittelwert ermitteln 
mean_k_b = mean(kinder_bio) 
mean_kk_b = mean(data.matrix(keine_kinder_bio)) #mean funktioniert nicht immer mit dt

# t.test durchführen
t.test(kinder_bio, keine_kinder_bio)

#--> Können H0 nicht verwerfen da p.value > alpha deshalb müssen wir bei der H0 hypo bleiben


```







## 2 Hypothese: Robinson G ̈aste sind bereit fu ̈r Bionahrung einen Aufschlag zu zahlen


```{r}
# daten und var spezifizieren 
bio_aufschlag = knn_fragebogen$f18_2

#plot --> Erkennbar dass Bereitschaft da wäre
hist(bio_aufschlag)


# daten und var spezifizieren 
aufschlag_abschrecken = knn_fragebogen$f18_9
#plot
hist(aufschlag_abschrecken)

# t.test für statistischen Nachweis
t.test(bio_aufschlag, aufschlag_abschrecken)

# weitere Möglichkeit: einseitiger t.test wo 4 als neutral gilt
t.test(bio_aufschlag, mu = 4, alternative = 'less')
# --> p.value<alpha 









```






## 3 Hypothese: Bionahrung besitzt das Potenzial ROBINSON als Marke zu st ̈arken.

Was verbinden die Kunden mit der Marken Robinson?

```{r}
#für marke robinson relevanten spalten zusammenführen 
marke_robinson = cbind(knn_fragebogen$f3_1,knn_fragebogen$f3_2,knn_fragebogen$f3_3,knn_fragebogen$f3_4,knn_fragebogen$f3_5,knn_fragebogen$f3_6,knn_fragebogen$f3_7,knn_fragebogen$f3_8,knn_fragebogen$f3_9,knn_fragebogen$f3_10, knn_fragebogen$f3_11)

#mean ausrechnen 
col_means_r=colMeans(marke_robinson)

#plot 
plot(col_means_r)

#weiteren Wert in Betracht ziehen: Modalwert 
## mode function definieren 
modefunc <- function(x){
    tabresult <- tabulate(x)
    themode <- which(tabresult == max(tabresult))
    if(sum(tabresult == max(tabresult))>1) themode <- NA
    return(themode)
}

#columns
col_mode_r = apply(marke_robinson, 2, modefunc)

#plot
plot(col_mode_r)


```


Was verbinden die Kunden mit der 'Marke' Bio?

```{r}
#für marke robinson relevanten spalten zusammenführen 
marke_bio = cbind(knn_fragebogen$f15_1,knn_fragebogen$f15_2,knn_fragebogen$f15_3,knn_fragebogen$f15_4,knn_fragebogen$f15_5,knn_fragebogen$f15_6,knn_fragebogen$f15_7,knn_fragebogen$f15_8,knn_fragebogen$f15_9,knn_fragebogen$f15_10, knn_fragebogen$f15_11,knn_fragebogen$f15_12,knn_fragebogen$f15_13,knn_fragebogen$f15_14,knn_fragebogen$f15_15,knn_fragebogen$f15_16)

#mean ausrechnen 
col_means_b=colMeans(marke_bio)

#plot 
plot(col_means_b)

#weiteren Wert in Betracht ziehen: Modalwert 

#columns
col_mode_b = apply(marke_bio, 2, modefunc)

#plot
plot(col_mode_b)




```

Welche Attribute lassen einen Vergleich zu? 

Gutes Preis- / Leistungsverhältnis: f3_1 = f15_16
Umfassendes Wohlfühlangebot: f3_2 = f15_8
Sportlichkeit: f3_3 = f15_6
Kinderfreundlichkeit: f3_4 = NA
Hochwertiges Speisenangebot: f3_5 = f15_4
Abwechslungsreiches Speisenangebot: f3_6 = f15_5
Einzigartigkeit: f3_7 = f15_7 (Individualität) ??
Hohe Qualität: f3_8 = NA
Gesundheit: f3_9 = f15_3
Im Trend: f3_10 = f15_9
Genuss: f3_11 = f15_12

```{r}
# vergleichsdaten zusammenführen 
vergleichs_matrix = cbind(col_means_r[1],col_means_b[16], 
                          col_means_r[2], col_means_b[8], 
                          col_means_r[3], col_means_b[6],
                          col_means_r[5], col_means_b[4],
                          col_means_r[6], col_means_b[5],
                          col_means_r[7], col_means_b[7],
                          col_means_r[9], col_means_b[3],
                          col_means_r[10], col_means_b[9],
                          col_means_r[11], col_means_b[12])



#vergleichsmatrix plotten
barplot(vergleichs_matrix)

```











# Weitere Datenanalysen  

```{r}
# besteht überhaupt ein Bedarf an weiteren Gütesiegeln?
bedarf_an_gs = knn_fragebogen$f18_4

#hist
hist(bedarf_an_gs)

# einseitiger t.test 
t.test(bedarf_an_gs, mu = 4, alternative = 'less')

#p.value < alpha --> signifikanter Bedarf an Gütesiegeln



```








